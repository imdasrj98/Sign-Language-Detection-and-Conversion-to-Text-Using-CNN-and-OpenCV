{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import math\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    'a': 10,\n",
    "    'b': 11,\n",
    "    'c': 12,\n",
    "    'd': 13,\n",
    "    'e': 14,\n",
    "    'f': 15,\n",
    "    'g': 16,\n",
    "    'h': 17,\n",
    "    'i': 18,\n",
    "    'j': 19,\n",
    "    'k': 20,\n",
    "    'l': 21,\n",
    "    'm': 22,\n",
    "    'n': 23,\n",
    "    'o': 24,\n",
    "    'p': 25,\n",
    "    'q': 26,\n",
    "    'r': 27,\n",
    "    's': 28,\n",
    "    't': 29,\n",
    "    'u': 30,\n",
    "    'v': 31,\n",
    "    'w': 32,\n",
    "    'x': 33,\n",
    "    'y': 34,\n",
    "    'z': 35,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Debayan Das\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model('asl2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyGesture(handTrainImage):\n",
    "  handTrainImage = cv2.cvtColor(handTrainImage, cv2.COLOR_BGR2RGB)\n",
    "  img = Image.fromarray(handTrainImage)\n",
    "  img_w, img_h = img.size\n",
    "  M = max(img_w, img_h)\n",
    "  background = Image.new('RGB', (M, M), (0, 0, 0))\n",
    "  bg_w, bg_h = background.size\n",
    "  offset = ((bg_w - img_w) //2, (bg_h - img_h) //2)\n",
    "  background.paste(img, offset)\n",
    "  size = 400,400\n",
    "  background = background.resize(size, Image.ANTIALIAS)\n",
    "  open_cv_image = numpy.array(background)\n",
    "  background = open_cv_image.astype('float32')\n",
    "  background = background / 255\n",
    "  background = background.reshape((1,) + background.shape)\n",
    "  predictions = model.predict_classes(background)\n",
    "  Key=\"\"\n",
    "  for key in classes.keys():\n",
    "      if classes[key]==predictions[0]:\n",
    "        print(key)\n",
    "        Key=key\n",
    "        break\n",
    "  #print(predictions)\n",
    "  #key = (key for key, value in classes.items() if value == predictions[0])\n",
    "  return Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "t\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "l\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "l\n",
      "Gesture Detected\n",
      "s\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "c\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "p\n",
      "Gesture Detected\n",
      "c\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "g\n",
      "Gesture Detected\n",
      "o\n",
      "Gesture Detected\n",
      "c\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "b\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "b\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "c\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "l\n",
      "Gesture Detected\n",
      "l\n",
      "Gesture Detected\n",
      "i\n",
      "Gesture Detected\n",
      "k\n",
      "Gesture Detected\n",
      "k\n",
      "Gesture Detected\n",
      "b\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "v\n",
      "Gesture Detected\n",
      "u\n",
      "Gesture Detected\n",
      "a\n",
      "Gesture Detected\n",
      "a\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7164936a48b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskinRegion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mcontours\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchShapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevcnt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprevcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow('Camera Output')\n",
    "cv2.namedWindow('Hand')\n",
    "cv2.namedWindow('HandTrain')\n",
    "cv2.createTrackbar('B for min', 'Camera Output', 0, 255, nothing)\n",
    "cv2.createTrackbar('G for min', 'Camera Output', 0, 255, nothing)\n",
    "cv2.createTrackbar('R for min', 'Camera Output', 0, 255, nothing)\n",
    "cv2.createTrackbar('B for max', 'Camera Output', 0, 255, nothing)\n",
    "cv2.createTrackbar('G for max', 'Camera Output', 0, 255, nothing)\n",
    "cv2.createTrackbar('R for max', 'Camera Output', 0, 255, nothing)\n",
    "cv2.setTrackbarPos('B for min', 'Camera Output', 0)\n",
    "cv2.setTrackbarPos('G for min', 'Camera Output', 130)\n",
    "cv2.setTrackbarPos('R for min', 'Camera Output', 103)\n",
    "cv2.setTrackbarPos('B for max', 'Camera Output', 255)\n",
    "cv2.setTrackbarPos('G for max', 'Camera Output', 182)\n",
    "cv2.setTrackbarPos('R for max', 'Camera Output', 130)\n",
    "videoFrame = cv2.VideoCapture(0)\n",
    "keyPressed = -1\n",
    "palm_cascade = cv2.CascadeClassifier('palm.xml')\n",
    "x_crop_prev, y_crop_prev, w_crop_prev, h_crop_prev = 0, 0, 0, 0\n",
    "_, prevHandImage = videoFrame.read()\n",
    "prevcnt = numpy.array([], dtype=numpy.int32)\n",
    "gestureStatic = 0\n",
    "gestureDetected = 0\n",
    "while keyPressed < 0:\n",
    "    min_YCrCb = numpy.array([cv2.getTrackbarPos('B for min', 'Camera Output'),\n",
    "                             cv2.getTrackbarPos('G for min', 'Camera Output'),\n",
    "                             cv2.getTrackbarPos('R for min', 'Camera Output')], numpy.uint8)\n",
    "    max_YCrCb = numpy.array([cv2.getTrackbarPos('B for max', 'Camera Output'),\n",
    "                             cv2.getTrackbarPos('G for max', 'Camera Output'),\n",
    "                             cv2.getTrackbarPos('R for max', 'Camera Output')], numpy.uint8)\n",
    "    readSucsess, sourceImage = videoFrame.read()\n",
    "    imageYCrCb = cv2.cvtColor(sourceImage, cv2.COLOR_BGR2YCR_CB)\n",
    "    imageYCrCb = cv2.GaussianBlur(imageYCrCb, (5, 5), 0)\n",
    "    skinRegion = cv2.inRange(imageYCrCb, min_YCrCb, max_YCrCb)\n",
    "    contours, hierarchy = cv2.findContours(skinRegion, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    cnt = contours[0]\n",
    "    ret = cv2.matchShapes(cnt, prevcnt, 2, 0.0)\n",
    "    prevcnt = contours[0]\n",
    "    stencil = numpy.zeros(sourceImage.shape).astype(sourceImage.dtype)\n",
    "    color = [255, 255, 255]\n",
    "    cv2.fillPoly(stencil, [cnt], color)\n",
    "    handTrainImage = cv2.bitwise_and(sourceImage, stencil)\n",
    "    if (ret > 0.70):\n",
    "        gestureStatic = 0\n",
    "    else:\n",
    "        gestureStatic += 1\n",
    "    x_crop, y_crop, w_crop, h_crop = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(sourceImage, (x_crop, y_crop), (x_crop + w_crop, y_crop + h_crop), (0, 255, 0), 2)\n",
    "    if (abs(x_crop - x_crop_prev) > 50 or abs(y_crop - y_crop_prev) > 50 or\n",
    "                abs(w_crop - w_crop_prev) > 50 or abs(h_crop - h_crop_prev) > 50):\n",
    "        x_crop_prev = x_crop\n",
    "        y_crop_prev = y_crop\n",
    "        h_crop_prev = h_crop\n",
    "        w_crop_prev = w_crop\n",
    "    handImage = sourceImage.copy()[max(0, y_crop_prev - 50):y_crop_prev + h_crop_prev + 50,\n",
    "                max(0, x_crop_prev - 50):x_crop_prev + w_crop_prev + 50]\n",
    "    handTrainImage = handTrainImage[max(0, y_crop_prev - 15):y_crop_prev + h_crop_prev + 15,\n",
    "                     max(0, x_crop_prev - 15):x_crop_prev + w_crop_prev + 15]\n",
    "    if gestureStatic == 10:\n",
    "            gestureDetected = 10;\n",
    "            print(\"Gesture Detected\")\n",
    "            letterDetected = identifyGesture(handTrainImage)\n",
    "    if gestureDetected > 0:\n",
    "        if (letterDetected != None):\n",
    "            cv2.putText(sourceImage, letterDetected, (10, 400), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)\n",
    "        gestureDetected -= 1\n",
    "    gray = cv2.cvtColor(handImage, cv2.COLOR_BGR2HSV)\n",
    "    palm = palm_cascade.detectMultiScale(gray)\n",
    "    for (x, y, w, h) in palm:\n",
    "        cv2.rectangle(sourceImage, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        roi_color = sourceImage[y:y + h, x:x + w]\n",
    "    hull = cv2.convexHull(cnt, returnPoints=False)\n",
    "    defects = cv2.convexityDefects(cnt, hull)\n",
    "    count_defects = 0\n",
    "    for i in range(defects.shape[0]):\n",
    "        s, e, f, d = defects[i, 0]\n",
    "        start = tuple(cnt[s][0])\n",
    "        end = tuple(cnt[e][0])\n",
    "        far = tuple(cnt[f][0])\n",
    "        if count_defects == 0:\n",
    "            center_of_palm = far\n",
    "        a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
    "        b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)\n",
    "        c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)\n",
    "        angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c)) * 57\n",
    "        if angle <= 90:\n",
    "            count_defects += 1\n",
    "            if count_defects < 5:\n",
    "                # cv2.circle(sourceImage, far, 5, [0, 0, 255], -1)\n",
    "                center_of_palm = (far[0] + center_of_palm[0]) / 2, (far[1] + center_of_palm[1]) / 2\n",
    "        cv2.line(sourceImage, start, end, [0, 255, 0], 2)\n",
    "    cv2.drawContours(sourceImage, contours, 0, (0, 255, 0), 1)\n",
    "    cv2.imshow('Camera Output', sourceImage)\n",
    "    cv2.imshow('Hand', handImage)\n",
    "    cv2.imshow('HandTrain', handTrainImage)\n",
    "    keyPressed = cv2.waitKey(30)\n",
    "cv2.destroyWindow('Camera Output')\n",
    "videoFrame.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
